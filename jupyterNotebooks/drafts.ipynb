{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import utilities\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities\n",
    "\n",
    "\n",
    "class bandLimitedAngularSpectrumMethod:\n",
    "    def __init__(\n",
    "        self,\n",
    "        amplitudeTensor=None,\n",
    "        phaseTensor=None,\n",
    "        distances=torch.Tensor([0.0]),\n",
    "        pixel_pitch=3.74e-6,\n",
    "        wave_length=torch.tensor([639e-9, 515e-9, 473e-9]),\n",
    "        padding=False,\n",
    "        debug=False,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        if amplitudeTensor is None:\n",
    "            self.amplitudeTensor = (\n",
    "                utilities.amplitude_tensor_generator_for_phase_only_hologram(\n",
    "                    \".\\data\\images\\sample_hologram.png\"\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            self.amplitudeTensor = amplitudeTensor\n",
    "\n",
    "        if phaseTensor is None:\n",
    "            self.phaseTensor = utilities.phase_tensor_generator(\n",
    "                \".\\data\\images\\sample_hologram.png\"\n",
    "            )\n",
    "        else:\n",
    "            self.phaseTensor = phaseTensor\n",
    "\n",
    "        if not isinstance(self.amplitudeTensor, torch.Tensor) or not isinstance(\n",
    "            self.phaseTensor, torch.Tensor\n",
    "        ):\n",
    "            raise ValueError(\"Amplitude tensor or phase tensor is required\")\n",
    "        if self.amplitudeTensor.shape != self.phaseTensor.shape:\n",
    "            raise ValueError(\n",
    "                \"Amplitude and phase tensors must have the same shape, but got {} and {}.\".format(\n",
    "                    self.amplitudeTensor.shape, self.phaseTensor.shape\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.distances = distances\n",
    "        self.pixel_pitch = pixel_pitch\n",
    "        self.wave_length = wave_length\n",
    "\n",
    "        self.samplingRowNum = self.phaseTensor.shape[-2]\n",
    "        self.samplingColNum = self.phaseTensor.shape[-1]\n",
    "\n",
    "        self.padding = padding\n",
    "        self.debug = debug\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            device = utilities.try_gpu()\n",
    "        self.device = device\n",
    "\n",
    "    def frequencyMesh(self):\n",
    "        # generate the 2-D frequency mesh\n",
    "        self.freq_x = torch.fft.fftfreq(self.samplingRowNum, self.pixel_pitch)\n",
    "        self.freq_y = torch.fft.fftfreq(self.samplingColNum, self.pixel_pitch)\n",
    "\n",
    "        mesh_x_y = self.freq_x.unsqueeze(1) ** 2 + self.freq_y.unsqueeze(0) ** 2\n",
    "        mesh_wave_length = 1 / self.wave_length**2\n",
    "        mesh = torch.sqrt(\n",
    "            torch.clamp(\n",
    "                mesh_wave_length.unsqueeze(1).unsqueeze(2) - mesh_x_y.unsqueeze(0),\n",
    "                min=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if self.debug:\n",
    "            print(\n",
    "                \"The highest positive frequency is u = {} and v = {}.\".format(\n",
    "                    self.freq_x.max(), self.freq_y.max()\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "                \"The highest negative frequency is u = {} and v = {}.\".format(\n",
    "                    self.freq_x.min(), self.freq_y.min()\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "                \"The resolution of the frequency is u = {} and v = {}.\".format(\n",
    "                    self.freq_x[1] - self.freq_x[0], self.freq_y[1] - self.freq_y[0]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return mesh\n",
    "\n",
    "    def band_limited_mask(self):\n",
    "\n",
    "        S_height = (\n",
    "            self.samplingRowNum * self.pixel_pitch\n",
    "        )  # the height of the sampling plain\n",
    "        S_width = (\n",
    "            self.samplingColNum * self.pixel_pitch\n",
    "        )  # the width of the sampling plain\n",
    "\n",
    "        d_u = 1 / S_height\n",
    "        d_v = 1 / S_width\n",
    "\n",
    "        wave_length = self.wave_length.unsqueeze(0)\n",
    "        distances = self.distances.unsqueeze(1)\n",
    "\n",
    "        u_limit = 1 / (\n",
    "            math.sqrt((2 * d_u * distances) ** 2 + 1) * wave_length\n",
    "        )\n",
    "        v_limit = 1 / (\n",
    "            math.sqrt((2 * d_v * distances) ** 2 + 1) * wave_length\n",
    "        )\n",
    "        mask_u = torch.abs(self.freq_x).unsqueeze(0).unsqueeze(1).unsqueeze(\n",
    "            3\n",
    "        ) < u_limit.unsqueeze(2).unsqueeze(3)\n",
    "        mask_v = torch.abs(self.freq_y).unsqueeze(0).unsqueeze(1).unsqueeze(\n",
    "            2\n",
    "        ) < v_limit.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        mask = mask_u & mask_v\n",
    "\n",
    "        if self.debug:\n",
    "            print(\n",
    "                \"The maximum frequency is clipped to u = {} and v = {}.\".format(\n",
    "                    u_limit, v_limit\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def band_limited_angular_spectrum_multichannels(\n",
    "        self,\n",
    "        band_limit=True,\n",
    "        debug=False,\n",
    "    ):\n",
    "\n",
    "        dx = self.pixel_pitch  # the sampling interval\n",
    "        sample_u = self.amplitudeTensor.shape[1]\n",
    "        sample_v = self.amplitudeTensor.shape[2]\n",
    "        S_x = sample_u * dx  # the x-size of the hologram plain\n",
    "        S_y = sample_v * dx  # the y-size of the hologram plain\n",
    "\n",
    "        # generate the 2-D frequency mesh\n",
    "        freq_x = torch.fft.fftfreq(sample_u, dx)\n",
    "        freq_y = torch.fft.fftfreq(sample_v, dx)\n",
    "\n",
    "        freq_x_unsqueezed = freq_x.unsqueeze(1).expand(sample_u, sample_v)\n",
    "        freq_y_unsqueezed = freq_y.unsqueeze(0).expand(sample_u, sample_v)\n",
    "\n",
    "        freq_square = freq_x_unsqueezed**2 + freq_y_unsqueezed**2\n",
    "        freq_cube = freq_square.unsqueeze(0).repeat(3, 1, 1)\n",
    "\n",
    "        freq_max = 1 / self.wave_length**2\n",
    "        freq_max_cube = freq_max.unsqueeze(1).unsqueeze(2).repeat(1, sample_u, sample_v)\n",
    "\n",
    "        w_cube_0 = freq_max_cube - freq_cube\n",
    "        mask_w_cube = w_cube_0 > 0\n",
    "        w_cube = mask_w_cube * w_cube_0\n",
    "\n",
    "        mesh = self.frequencyMesh()\n",
    "        print(f\"the shape of mesh is {mesh.shape} and the shape of w_cube is {w_cube.shape}\")\n",
    "        assert torch.allclose(torch.sqrt(w_cube), mesh, atol=1e-6)\n",
    "\n",
    "        # transfer function\n",
    "        H_FR = torch.exp(2j * math.pi * self.distances * torch.sqrt(w_cube))\n",
    "        # H_FR = torch.exp(1j * math.pi * z * (2/wave_length.unsqueeze(1).unsqueeze(2)-wave_length.unsqueeze(1).unsqueeze(2)*freq_cube))\n",
    "        # print(H_FR.shape)\n",
    "\n",
    "        if band_limit:\n",
    "            # clipper the frequency\n",
    "            d_u = 1 / S_x  # S_x instead of 2 * S_x\n",
    "            d_v = 1 / S_y  # S_y instead of 2 * S_y\n",
    "            wave_length = self.wave_length\n",
    "            distances = self.distances\n",
    "            u_limit = 1 / (\n",
    "                math.sqrt((2 * d_u * distances) ** 2 + 1) * wave_length\n",
    "            )\n",
    "            v_limit = 1 / (\n",
    "                math.sqrt((2 * d_v * distances) ** 2 + 1) * wave_length\n",
    "            )\n",
    "            mask_u = torch.abs(freq_x).unsqueeze(0).repeat(3, 1) < u_limit.unsqueeze(\n",
    "                1\n",
    "            ).expand(3, sample_u)\n",
    "            mask_v = torch.abs(freq_y).unsqueeze(0).repeat(3, 1) < v_limit.unsqueeze(\n",
    "                1\n",
    "            ).expand(3, sample_v)\n",
    "            mask = mask_u.unsqueeze(2) & mask_v.unsqueeze(1)\n",
    "\n",
    "            # print(f\"the shape of mask is {mask.shape} and the shape of self.band_limited_mask() is {self.band_limited_mask().shape}\")\n",
    "            assert torch.allclose(mask, self.band_limited_mask())\n",
    "\n",
    "            H_FR = H_FR * mask\n",
    "\n",
    "        sourcePlain = utilities.complex_plain(self.amplitudeTensor, self.phaseTensor)\n",
    "        G_0 = torch.fft.fft2(sourcePlain)\n",
    "        G_z = G_0 * H_FR\n",
    "\n",
    "        # inverse fourier transform\n",
    "        g_z_complex = torch.fft.ifft2(G_z)\n",
    "\n",
    "        if debug:\n",
    "            if mask.sum() == sample_u * sample_v * 3:\n",
    "                print(\n",
    "                    \"The maximum frequency is clipped to u = {} and v = {}.\".format(\n",
    "                        u_limit, v_limit\n",
    "                    )\n",
    "                )\n",
    "                print(\"The clipper is NOT working............\")\n",
    "            else:\n",
    "                print(\n",
    "                    \"The maximum frequency is clipped to u = {} and v = {}.\".format(\n",
    "                        u_limit, v_limit\n",
    "                    )\n",
    "                )\n",
    "                print(\"The clipper is working............\")\n",
    "\n",
    "        return g_z_complex\n",
    "\n",
    "\n",
    "A = bandLimitedAngularSpectrumMethod(distances=torch.Tensor([2.5e-3]),debug=False)\n",
    "g_z_complex = A.band_limited_angular_spectrum_multichannels()\n",
    "print(g_z_complex.shape)\n",
    "utilities.diffraction_plotter(utilities.intensity_calculator(g_z_complex), 1.0, rgb_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个示例四维张量\n",
    "tensor = torch.randn(2, 3, 4, 5)\n",
    "\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "\n",
    "# 第一步：沿最后一个维度计算最大值\n",
    "max_along_width, _ = torch.max(tensor, dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Shape after max along width:\", max_along_width.shape)\n",
    "\n",
    "# 第二步：沿倒数第二个维度计算最大值\n",
    "max_along_height, _ = torch.max(max_along_width, dim=-2, keepdim=True)\n",
    "\n",
    "print(\"Shape after max along height:\", max_along_height.shape)\n",
    "\n",
    "# 最终结果是保留了原始张量的形状，但在最后两个维度上的值是每个height x width 矩阵的最大值\n",
    "print(max_along_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utilities\n",
    "from band_limited_angular_spectrum_method import bandLimitedAngularSpectrumMethod\n",
    "\n",
    "distances = torch.Tensor([-2.5e-3, 0, 2.5e-3])\n",
    "\n",
    "A = bandLimitedAngularSpectrumMethod(distances=distances, debug=False)\n",
    "g_z_complex = A.band_limited_angular_spectrum_multichannels()\n",
    "utilities.multi_depth_diffraction_plotter(\n",
    "    utilities.intensity_calculator(g_z_complex), distances, rgb_img=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_x = torch.rand(4)\n",
    "freq_y = torch.rand(3)\n",
    "freq_mesh_x_y = freq_x.unsqueeze(1)**2 + freq_y.unsqueeze(0)**2\n",
    "print(freq_x)\n",
    "print(freq_y)\n",
    "print(freq_mesh_x_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorX = torch.rand(4,3,5,6)\n",
    "print(tensorX)\n",
    "print(tensorX.size())\n",
    "print(tensorX.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utilities\n",
    "tensorX = torch.rand(3,5,6)\n",
    "print(tensorX)\n",
    "utilities.diffraction_plotter(tensorX, 12, False, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = torch.fft.fftfreq(9, 1/9)\n",
    "freq_with_fftshift = torch.fft.fftshift(freq)\n",
    "freq_with_ifftshift = torch.fft.ifftshift(freq)\n",
    "print(freq)\n",
    "print(freq_with_fftshift)\n",
    "print(freq_with_ifftshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "field_padded = torch.rand(1920,1080).to('cuda')\n",
    "H =torch.rand(1920,1080).to('cuda')\n",
    "aperture = torch.rand(1920,1080).to('cuda')\n",
    "\n",
    "\n",
    "# original code\n",
    "U1_1 = torch.fft.fftshift(torch.fft.fft2(torch.fft.fftshift(field_padded)))\n",
    "U2_1 = H * aperture * U1_1\n",
    "result_1 = torch.fft.ifftshift(torch.fft.ifft2(torch.fft.ifftshift(U2_1)))\n",
    "\n",
    "\n",
    "# remove the fftshift and ifftshift in the spatial domain\n",
    "U1_2 = torch.fft.fftshift(torch.fft.fft2(field_padded))\n",
    "U2_2 = H * aperture * U1_2\n",
    "result_2 = torch.fft.ifft2(torch.fft.ifftshift(U2_2))\n",
    "\n",
    "assert torch.allclose(result_1, result_2, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def cpu_timer(operation,reapeat=100):\n",
    "    total_time = 0\n",
    "    for _ in range(reapeat):\n",
    "        start_time = time.perf_counter()\n",
    "        operation()\n",
    "        end_time = time.perf_counter()\n",
    "        total_time += end_time - start_time\n",
    "    return total_time/reapeat\n",
    "\n",
    "def gpu_timer(operation,reapeat=100):\n",
    "    total_time = 0\n",
    "    # clean the cache on gpu\n",
    "    torch.cuda.empty_cache()\n",
    "    for _ in range(reapeat):\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = torch.cuda.Event(enable_timing=True)\n",
    "        end_time = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        start_time.record()\n",
    "        operation()\n",
    "        end_time.record()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        total_time += start_time.elapsed_time(end_time)\n",
    "    return total_time/reapeat\n",
    "\n",
    "def original_code(field_padded, H, aperture):\n",
    "    U1 = torch.fft.fftshift(torch.fft.fft2(torch.fft.fftshift(field_padded)))\n",
    "    U2 = H * aperture * U1\n",
    "    return torch.fft.ifftshift(torch.fft.ifft2(torch.fft.ifftshift(U2)))\n",
    "\n",
    "def modified_code(field_padded, H, aperture):\n",
    "    U1 = torch.fft.fftshift(torch.fft.fft2(field_padded))\n",
    "    U2 = H * aperture * U1\n",
    "    return torch.fft.ifft2(torch.fft.ifftshift(U2))\n",
    "\n",
    "# comparison on cpu\n",
    "field_padded = torch.rand(1920,1080)\n",
    "H =torch.rand(1920,1080)\n",
    "aperture = torch.rand(1920,1080)\n",
    "\n",
    "original_time = cpu_timer(lambda: original_code(field_padded, H, aperture))\n",
    "modified_time = cpu_timer(lambda: modified_code(field_padded, H, aperture))\n",
    "print(f'Original code on CPU: {original_time:.8f} ms')\n",
    "print(f'Modified code on CPU: {modified_time:.8f} ms')\n",
    "\n",
    "# check if the results are the same\n",
    "assert torch.allclose(original_code(field_padded, H, aperture), modified_code(field_padded, H, aperture), atol=1e-6)\n",
    "\n",
    "# comparison on gpu\n",
    "field_padded = field_padded.to('cuda')\n",
    "H = H.to('cuda')\n",
    "aperture = aperture.to('cuda')\n",
    "\n",
    "original_time = gpu_timer(lambda: original_code(field_padded, H, aperture))\n",
    "modified_time = gpu_timer(lambda: modified_code(field_padded, H, aperture))\n",
    "print(f'Original code on GPU: {original_time:.8f} ms')\n",
    "print(f'Modified code on GPU: {modified_time:.8f} ms')\n",
    "\n",
    "# check if the results are the same\n",
    "assert torch.allclose(original_code(field_padded, H, aperture), modified_code(field_padded, H, aperture), atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "# original code\n",
    "U1_1 = torch.fft.fftshift(torch.fft.fft2(torch.fft.fftshift(field_padded)))\n",
    "U2_1 = H * aperture * U1_1\n",
    "result_1 = torch.fft.ifftshift(torch.fft.ifft2(torch.fft.ifftshift(U2_1)))\n",
    "\n",
    "# print the time\n",
    "%timeit torch.fft.fftshift(torch.fft.fft2(torch.fft.fftshift(field_padded)))\n",
    "%timeit torch.fft.fftshift(torch.fft.fft2(field_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "def normal(x, mu, sigma):\n",
    "    p = 1 / math.sqrt(2 * math.pi * sigma**2)\n",
    "    return p * np.exp(-0.5 * (x - mu) ** 2 / sigma**2)\n",
    "\n",
    "\n",
    "# Use NumPy again for visualization\n",
    "x = np.arange(-7, 7, 0.01)\n",
    "\n",
    "# Mean and standard deviation pairs\n",
    "params = [(0, 1), (0, 2), (3, 1)]\n",
    "plt.figure(figsize=(4.5, 2.5))\n",
    "plt.plot(x,normal(x, *params[0]), linewidth=2, label='mean=0, std=1')\n",
    "plt.plot(x,normal(x, *params[1]), linewidth=2, label='mean=0, std=2')\n",
    "plt.plot(x,normal(x, *params[2]), linewidth=2, label='mean=3, std=1')\n",
    "plt.legend()\n",
    "plt.title('Normal distribution')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成一个简单的二维全息图（正弦波干涉图样）\n",
    "def generate_hologram(size, frequency):\n",
    "    x = np.linspace(-np.pi, np.pi, size)\n",
    "    y = np.linspace(-np.pi, np.pi, size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    hologram = np.sin(frequency * X) * np.sin(frequency * Y)\n",
    "    return hologram\n",
    "\n",
    "size = 256\n",
    "frequency = 10\n",
    "hologram = generate_hologram(size, frequency)\n",
    "\n",
    "plt.imshow(hologram, cmap='gray')\n",
    "plt.title(\"Generated Hologram\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "# 生成理想的点扩散函数（高斯函数模拟）\n",
    "def gaussian_psf(size, sigma):\n",
    "    x = np.linspace(-size // 2, size // 2, size)\n",
    "    y = np.linspace(-size // 2, size // 2, size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    psf = np.exp(-(X**2 + Y**2) / (2 * sigma**2))\n",
    "    psf /= np.sum(psf)\n",
    "    return psf\n",
    "\n",
    "psf_size = 20\n",
    "sigma = 5  # 模拟数值孔径和波长的影响\n",
    "psf = gaussian_psf(psf_size, sigma)\n",
    "\n",
    "# plot the point spread function\n",
    "plt.imshow(psf, cmap='gray')\n",
    "plt.title(\"Point Spread Function\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 模拟相机对全息图的拍摄过程（卷积操作）\n",
    "captured_hologram = convolve2d(hologram, psf, mode='same')\n",
    "\n",
    "plt.imshow(captured_hologram, cmap='gray')\n",
    "plt.title(\"Captured Hologram with Diffraction-Limited Optics\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义参数\n",
    "alpha = 6.0\n",
    "x = np.linspace(-10, 10, 400)\n",
    "\n",
    "# 计算二次相位指数函数\n",
    "quadratic_phase = np.exp(1j * alpha * x**2)\n",
    "\n",
    "# 分别绘制实部和虚部\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, np.real(quadratic_phase))\n",
    "plt.title('Real Part of $e^{j \\\\alpha x^2}$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Real Part')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, np.imag(quadratic_phase))\n",
    "plt.title('Imaginary Part of $e^{j \\\\alpha x^2}$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Imaginary Part')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_gpus():  #@save\n",
    "    \"\"\"Get the number of available GPUs.\"\"\"\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "num_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 检查是否有 GPU 可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 生成一些示例数据\n",
    "x_train = torch.randn(100, 10)\n",
    "y_train = torch.randn(100, 1)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型并移动到 GPU\n",
    "model = SimpleNN().to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        # 将数据移动到 GPU\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_spectrum(\n",
    "    source_plain=-1,\n",
    "    amplitude_plain=-1,\n",
    "    phase_plain=-1,\n",
    "    wave_length=1,\n",
    "    pixel_pitch = 3.74e-6,\n",
    "    z=100 * 2048, # the propagation distance\n",
    "    sample_u=1024,  # the number of pixels in x-axis\n",
    "    sample_v=1024,  # the number of pixels in y-axis\n",
    "    clipper_u=-1,\n",
    "    clipper_v=-1,\n",
    "):\n",
    "    dx = 2 * pixel_pitch  # the sample interval\n",
    "\n",
    "    N_u = 2 * sample_u\n",
    "    N_v = 2 * sample_v\n",
    "\n",
    "\n",
    "    # generate the 2-D frequency mesh\n",
    "    freq_x = torch.fft.fftfreq(N_u, dx)\n",
    "    freq_y = torch.fft.fftfreq(N_v, dx)\n",
    "\n",
    "    freq_x = torch.unsqueeze(freq_x, dim=1).expand(\n",
    "        -1, len(freq_y)\n",
    "    )  # expand to len(y) columns\n",
    "    freq_y = torch.unsqueeze(freq_y, dim=0).expand(\n",
    "        len(freq_x), -1\n",
    "    )  # expand to len(x) rows\n",
    "    freq_square = freq_x**2 + freq_y**2\n",
    "\n",
    "    freq_squre_max = torch.full((N_u, N_v), 1 / wave_length) ** 2\n",
    "    w_square_0 = freq_squre_max - freq_square\n",
    "    mask = w_square_0 > 0\n",
    "    w_square = torch.where(mask, w_square_0, 0)\n",
    "\n",
    "    # transfer function\n",
    "    H_FR = torch.empty((N_u, N_v), dtype=torch.complex64)\n",
    "    H_FR = torch.exp(2j * math.pi * z * torch.sqrt(w_square))\n",
    "\n",
    "    # generate the source plain\n",
    "    g_0 = torch.zeros((N_u, N_v))\n",
    "    if isinstance(source_plain, torch.Tensor):\n",
    "        # load the picture\n",
    "        g_0[\n",
    "            N_u // 2 - sample_u // 2 : N_u // 2 + sample_u // 2,\n",
    "            N_v // 2 - sample_v // 2 : N_v // 2 + sample_v // 2,\n",
    "        ] = source_plain\n",
    "        G_0 = torch.fft.fft2(g_0)\n",
    "    elif (isinstance(amplitude_plain, torch.Tensor) & isinstance(phase_plain, torch.Tensor)):\n",
    "        G_0 = amplitude_plain*torch.exp(1j*phase_plain) # generate the source plain in frequency domain\n",
    "    else:\n",
    "        print(\"Error: invalid input\")\n",
    "        return\n",
    "\n",
    "    # the spectrum in the destination plain\n",
    "    G_z = G_0 * H_FR\n",
    "\n",
    "\n",
    "    G_z = torch.fft.fftshift(G_z)\n",
    "    # clip the frequency in x\n",
    "    if clipper_u == -1:\n",
    "        pass\n",
    "    else:\n",
    "        G_z[: N_u // 2 + 1 - clipper_u, :] = 0\n",
    "        G_z[N_u // 2 + clipper_u :, :] = 0\n",
    "\n",
    "    # clip the frequency in y\n",
    "    if clipper_v == -1:\n",
    "        pass\n",
    "    else:\n",
    "        G_z[:, : N_v // 2 + 1 - clipper_v] = 0\n",
    "        G_z[:, N_v // 2 + clipper_v :] = 0\n",
    "\n",
    "    G_z = torch.fft.ifftshift(G_z)\n",
    "\n",
    "\n",
    "    # 目标平面\n",
    "    g_z = torch.fft.ifft2(G_z).abs()\n",
    "\n",
    "    return (\n",
    "        H_FR.real,\n",
    "        g_z[\n",
    "            int(N_u / 2) - sample_u // 2 : int(N_u / 2) + sample_u // 2,\n",
    "            int(N_v / 2) - sample_v // 2 : int(N_v / 2) + sample_v // 2,\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_limited_angular_spectrum(\n",
    "    source_plain=-1,\n",
    "    amplitude_plain=-1,\n",
    "    phase_plain=-1,\n",
    "    wave_length=1,\n",
    "    pixel_pitch=3.74e-6,\n",
    "    z=100 * 2048,\n",
    "    sample_u=1024,\n",
    "    sample_v=1024,\n",
    "):\n",
    "    dx = 2 * pixel_pitch  # the sampling interval\n",
    "    S_x = sample_u * dx\n",
    "    S_y = sample_v * dx\n",
    "\n",
    "    N_u = 2 * sample_u\n",
    "    N_v = 2 * sample_v\n",
    "\n",
    "    freq_u = torch.fft.fftfreq(N_u, dx)\n",
    "    freq_u = torch.fft.fftshift(freq_u)\n",
    "\n",
    "    freq_v = torch.fft.fftfreq(N_v, dx)\n",
    "    freq_v = torch.fft.fftshift(freq_v)\n",
    "\n",
    "    d_u = 1 / (2 * S_x)\n",
    "    d_v = 1 / (2 * S_y)\n",
    "    u_limit = 1 / (math.sqrt((2 * d_u * z) ** 2 + 1) * wave_length)\n",
    "    v_limit = 1 / (math.sqrt((2 * d_v * z) ** 2 + 1) * wave_length)\n",
    "\n",
    "    mask_u = abs(freq_u) <= (u_limit)\n",
    "    if torch.all(mask_u):\n",
    "        clipper_u = -1\n",
    "        max_frequency_retained_u = abs(freq_u[0])\n",
    "    else:\n",
    "        first_true_index = torch.argmax(mask_u.to(torch.int))\n",
    "        clipper_u = N_u // 2 + 1 - first_true_index\n",
    "        max_frequency_retained_u = abs(freq_u[first_true_index])\n",
    "\n",
    "    mask_v = abs(freq_v) <= (v_limit)\n",
    "    if torch.all(mask_v):\n",
    "        clipper_v = -1\n",
    "        max_frequency_retained_v = abs(freq_v[0])\n",
    "    else:\n",
    "        first_true_index = torch.argmax(mask_v.to(torch.int))\n",
    "        clipper_v = N_v // 2 + 1 - first_true_index\n",
    "        max_frequency_retained_v = abs(freq_v[first_true_index])\n",
    "\n",
    "    H_FR_real, g_z = angular_spectrum(source_plain,amplitude_plain, phase_plain, wave_length, pixel_pitch, z, sample_u, sample_v, clipper_u, clipper_v)\n",
    "\n",
    "    print(\n",
    "        f\"u: cut-off frequency {(u_limit)} : set clipper_n to be {clipper_u} (the max frequency retained : {max_frequency_retained_u})\\n\",\n",
    "        f\"v: cut-off frequency {(v_limit)} : set clipper_n to be {clipper_v} (the max frequency retained : {max_frequency_retained_v})\\n\",\n",
    "    )\n",
    "\n",
    "    return max_frequency_retained_u, max_frequency_retained_v, g_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_image2phase_tensor(image_path):\n",
    "    image_grey = Image.open(image_path).convert(\"L\") # convert the image to gray scale\n",
    "    print(image_grey.size)\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tensor = transform(image_grey)\n",
    "    print(image_tensor.shape)\n",
    "    image_tensor = image_tensor.squeeze(0) # delete a dimension from the tensor\n",
    "    image_tensor_normalized = image_tensor * 2 * math.pi\n",
    "    return image_tensor_normalized # return the tensor between 0 and 2*pi\n",
    "    \n",
    "phaseTensor = phase_image2phase_tensor(\"sample_hologram.png\")\n",
    "phaseTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude_tensor(image_path):\n",
    "    image_shape = Image.open(image_path).size\n",
    "    # generate 2-D amplitude tensor same size as the phase tensor all values are 1.0\n",
    "    amplitude_tensor = torch.ones(image_shape)\n",
    "    return amplitude_tensor.T\n",
    "amplitudeTensor = amplitude_tensor(\"sample_hologram.png\")\n",
    "amplitudeTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frequency_retained_u, max_frequency_retained_v, g_z = band_limited_angular_spectrum(\n",
    "    source_plain=-1,\n",
    "    amplitude_plain=amplitude_tensor(\"sample_hologram.png\"),\n",
    "    phase_plain=phase_image2phase_tensor(\"sample_hologram.png\"),\n",
    "    wave_length=639e-9,\n",
    "    pixel_pitch=3.74e-6,\n",
    "    z=2.5e-3,\n",
    "    sample_u=2400 // 2,\n",
    "    sample_v=4094 // 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v, band_limited_g_z_2D = band_limited_angular_spectrum(\n",
    "    source_plain=-1,\n",
    "    amplitude_plain=amplitude_tensor(\"sample_hologram.png\"),\n",
    "    phase_plain=phase_image2phase_tensor(\"sample_hologram.png\"),\n",
    "    wave_length=639e-9,\n",
    "    pixel_pitch=3.74e-6,\n",
    "    z=2.5e-3,\n",
    "    sample_u=2400 // 2,\n",
    "    sample_v=4094 // 2,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
    "\n",
    "# im1 = axes[0].imshow(g_z_2D, cmap=\"gray\")\n",
    "# fig.colorbar(im1, ax=axes[0])\n",
    "# axes[0].set_title(\"original method\")\n",
    "\n",
    "im2 = axes[1].imshow(band_limited_g_z_2D, cmap=\"gray\")\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "axes[1].set_title(\"with band limit\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
